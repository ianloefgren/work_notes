# Improving Human-Robot Collaboration via Robot Self-Confidence
# 10-20-2017
## presentation by Brett Israelsen

## Research Vision
- people need to use Artifically Intelligent Agents (AIAs) appropriately
    - an AIA is a goal-oriented system that is able to do at least one of:
        - reasoning
        - planning
        - learning
        - perception
        - and more!
    - capabilties are sources of assurance
- what feedback can AIAs provide humans that will affect their trust?
- AIAs and humans need to work together

## Details

### trust-related actions and assurances
- an AIA can perform task-based actions and provide assurances to the user
- the user can percieve these assurances, and then perform trust-related behaviors
    - includes assigning the AIA tasks
    - assume the user has no total knowledge or control of the capabilities of the AIA
- the AIA is able to observe the effects of the the assurances performed
- implicit and explict assurances
    - implicit assurances
        - not designed for
        - ex. people like the manufacturer, the AIA is in good repair
    - explicit assurances
        - assurances designed to be assurances
    - the line between the two are intention of the designer

### An assurance called "Self Confidence"
- an assurance that should allow the user to **easily** understand the autonomous system's capabilities and limitations
- a metric w/ five factors, between -1 and 1
- aimed at user's competance trust component, i.e. the beief of the user that the AIA is competent


## Ideas to think about
